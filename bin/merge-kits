#!/usr/bin/env python3

import argparse
import logging
import sys
from concurrent.futures import as_completed
from concurrent.futures.thread import ThreadPoolExecutor

from dict_tools.data import NamespaceDict

from metatools.config.merge import MergeConfig
from subpop.hub import Hub

hub = Hub()

import dyne.org.funtoo.metatools.merge as merge


class MergeError(Exception):
	pass

# TODO: we need to set the IntegrityScope which gets passed to 'doit'.
# TODO: we likely should deprecate indy kits in favor of autogenned kits using indy kits as a source kit.
# TODO: allow certain kits like llvm-kit to be generated *before* other kits.
# TODO: clean up main_thread() and in general make things cleaner.
# TODO: drop all indy-kit-specific code to make things cleaner.
# TODO: add a means to copy an entire kit, without listing everything in packages.yaml.



class ThreadPipeline:
	pass

async def main_thread(args):

	await merge.launch(MergeConfig, release=args.release, prod=args.prod, push=not args.nopush, create_branches=args.create_branches)

	merge.metadata.cleanup_error_logs()
	thread_pipelines = merge.sources.get_kits_in_correct_processing_order()

	# This will generate core-kit, as well as all other kits:
	for source in thread_keys:
		kit_dict_list = thread_groups[source]
		regen_futures = []
		with ThreadPoolExecutor(max_workers=4) as executor:

			# Initialize sources based on the settings of the first kit in the group (they are all identical)
			kit_dict = kit_dict_list[0]

			if kit_dict["kind"] == "independent":
				raise NotImplementedError()

			# This initializes the "source repos" that are used to grab catpkgs from to generate this kit:
			await merge.sources.initialize_sources(kit_dict["source"])

			for kit_dict in kit_dict_list:
				# For simplicity, set up a context variable to pass around, where ctx.kit contains the kit information:
				ctx = NamespaceDict()
				ctx["kit"] = NamespaceDict(kit_dict)
				# merge.kit.generate_kit does the real work:
				future = executor.submit(hub.run_async_adapter, merge.kit.generate_kit, ctx)
				regen_futures.append(future)
			for future in as_completed(regen_futures):
				ctx, tree_obj, tree_sha1 = future.result()
				merge.model.kit_results[ctx.kit.name] = (ctx, tree_obj, tree_sha1)
				merge.model.kit_sha1s[ctx.kit.name][ctx.kit.branch] = tree_sha1

	# Create meta-repo commit referencing our updated kits:
	merge.kit.generate_metarepo_metadata(merge.model.kit_sha1s)
	merge.model.meta_repo.gitCommit(message="kit updates", skip=["kits"], push=merge.model.push)

	if not merge.model.prod:
		# check out preferred kit branches, because there's a good chance we'll be using it locally.
		for name, ctx in merge.sources.get_kit_preferred_branches().items():
			logging.warning(f"Checking out {name} {ctx.kit.branch}...")
			await merge.kit.checkout_kit(ctx, pull=False)

	if not merge.model.mirror_repos:
		merge.metadata.display_error_summary()
		return

	# Mirroring to GitHub happens here:

	merge.kit.mirror_all_repositories()
	merge.metadata.display_error_summary()


CLI_CONFIG = {
	"force": {"action": "store_true", "default": False},
	"nopush": {"action": "store_true", "default": False},
	"prod": {"action": "store_true", "default": False},
	"db": {"action": "store_true", "default": False},
	"create_branches": {"action": "store_true", "default": False},
	"release": {"positional": True},
}


def parse_args():
	ap = argparse.ArgumentParser()
	for arg, kwargs in CLI_CONFIG.items():
		if "os" in kwargs:
			del kwargs["os"]
		if "positional" in kwargs and kwargs["positional"]:
			new_kwargs = kwargs.copy()
			del new_kwargs["positional"]
			ap.add_argument(arg, **new_kwargs)
		else:
			ap.add_argument("--" + arg, **kwargs)
	return ap.parse_args()


if __name__ == "__main__":
	args = parse_args()
	hub.LOOP.run_until_complete(main_thread(args))
	sys.exit(0)

# vim: ts=4 sw=4 noet
