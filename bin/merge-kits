#!/usr/bin/env python3

import argparse
import logging
import sys
from concurrent.futures import as_completed
from concurrent.futures.thread import ThreadPoolExecutor

from metatools.config.merge import MergeConfig
from subpop.hub import Hub

hub = Hub()

import dyne.org.funtoo.metatools.merge as merge


class MergeError(Exception):
	pass

# TODO: we need to set the IntegrityScope which gets passed to 'doit'.
# TODO: we likely should deprecate indy kits in favor of autogenned kits using indy kits as a source kit.
# TODO: allow certain kits like llvm-kit to be generated *before* other kits.
# TODO: clean up main_thread() and in general make things cleaner.
# TODO: drop all indy-kit-specific code to make things cleaner.
# TODO: add a means to copy an entire kit, without listing everything in packages.yaml.


class MetaRepo:
	# TODO: have this hold kit sha1's?
	pass


class ParallelJobSet:
	pass


async def main_thread(args):

	await merge.launch(MergeConfig, release=args.release, prod=args.prod, push=not args.nopush, create_branches=args.create_branches)

	merge.metadata.cleanup_error_logs()
	# TODO: this is pseudo-code:

	parallel_job_sets = merge.sources.get_kits_in_correct_processing_order()
	for job_set in parallel_job_sets:
		# The idea here is that every pipeline has the same set of source repos, so if we do setup then the source repos
		# then we are ready to go.
		await job_set.setup()
		regen_futures = []
		with ThreadPoolExecutor(max_workers=8) as executor:
			for kit_job in job_set:
				future = executor.submit(hub.run_async_adapter, kit_job.run)
				regen_futures.append(future)
			# TODO: just have kit_job.run store this in kit attributes so we can get them later.
			for future in as_completed(regen_futures):
				ctx, tree_obj, tree_sha1 = future.result()
				merge.model.kit_results[ctx.kit.name] = (ctx, tree_obj, tree_sha1)
				merge.model.kit_sha1s[ctx.kit.name][ctx.kit.branch] = tree_sha1


	# # This will generate core-kit, as well as all other kits:
	# for source in thread_keys:
	# 	kit_dict_list = thread_groups[source]
	# 	regen_futures = []
	# 	with ThreadPoolExecutor(max_workers=4) as executor:
	#
	# 		# Initialize sources based on the settings of the first kit in the group (they are all identical)
	# 		kit_dict = kit_dict_list[0]
	#
	# 		if kit_dict["kind"] == "independent":
	# 			raise NotImplementedError()
	#
	# 		# This initializes the "source repos" that are used to grab catpkgs from to generate this kit:
	# 		await merge.sources.initialize_sources(kit_dict["source"])
	#
	# 		for kit_dict in kit_dict_list:
	# 			# For simplicity, set up a context variable to pass around, where ctx.kit contains the kit information:
	# 			ctx = NamespaceDict()
	# 			ctx["kit"] = NamespaceDict(kit_dict)
	# 			# merge.kit.generate_kit does the real work:
	# 			future = executor.submit(hub.run_async_adapter, merge.kit.generate_kit, ctx)
	# 			regen_futures.append(future)
	# 		for future in as_completed(regen_futures):
	# 			ctx, tree_obj, tree_sha1 = future.result()
	# 			merge.model.kit_results[ctx.kit.name] = (ctx, tree_obj, tree_sha1)
	# 			merge.model.kit_sha1s[ctx.kit.name][ctx.kit.branch] = tree_sha1

	# Create meta-repo commit referencing our updated kits:
	merge.kit.generate_metarepo_metadata(merge.model.kit_sha1s)
	merge.model.meta_repo.gitCommit(message="kit updates", skip=["kits"], push=merge.model.push)

	if not merge.model.prod:
		# check out preferred kit branches, because there's a good chance we'll be using it locally.
		for name, ctx in merge.sources.get_kit_preferred_branches().items():
			logging.warning(f"Checking out {name} {ctx.kit.branch}...")
			await merge.kit.checkout_kit(ctx, pull=False)

	if not merge.model.mirror_repos:
		merge.metadata.display_error_summary()
		return

	# Mirroring to GitHub happens here:

	merge.kit.mirror_all_repositories()
	merge.metadata.display_error_summary()


CLI_CONFIG = {
	"force": {"action": "store_true", "default": False},
	"nopush": {"action": "store_true", "default": False},
	"prod": {"action": "store_true", "default": False},
	"db": {"action": "store_true", "default": False},
	"create_branches": {"action": "store_true", "default": False},
	"release": {"positional": True},
}


def parse_args():
	ap = argparse.ArgumentParser()
	for arg, kwargs in CLI_CONFIG.items():
		if "os" in kwargs:
			del kwargs["os"]
		if "positional" in kwargs and kwargs["positional"]:
			new_kwargs = kwargs.copy()
			del new_kwargs["positional"]
			ap.add_argument(arg, **new_kwargs)
		else:
			ap.add_argument("--" + arg, **kwargs)
	return ap.parse_args()


if __name__ == "__main__":
	args = parse_args()
	hub.LOOP.run_until_complete(main_thread(args))
	sys.exit(0)

# vim: ts=4 sw=4 noet
